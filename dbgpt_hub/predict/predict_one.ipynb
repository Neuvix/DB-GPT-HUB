{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/dbgpt_hub/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "from dbgpt_hub.data_process.data_utils import extract_sql_prompt_dataset\n",
    "from dbgpt_hub.llm_base.chat_model import ChatModel\n",
    "from dbgpt_hub.dataset_util.excel_processor import ExcelProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 准备预测table数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_PROMPT = '''I want you to act as a SQL terminal in front of an example database, \\\n",
    "         you need only to return the table name to me.Below is an instruction that describes a task, \\\n",
    "         Write a response that appropriately completes the request.\\n\"\n",
    "        \"##Instruction:\\n{}\\n###Input:\\n{}\\n\\n###Response:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_table_data(input: Optional[str]) -> str:\n",
    "    db_id = \"tp_mis\"\n",
    "    all_tables = ExcelProcessor().read_excel('/root/Neuvix/DB-GPT-HUB/dbgpt_hub/data/tp_mis/all_table.xlsx')\n",
    "    tables = ', '.join(str(item[1]) for item in all_tables)\n",
    "    tables_description = ', '.join(str(item[2]) for item in all_tables)\n",
    "    instruction = '''I want you to act as a SQL terminal in front of an example database, you need only to return the table name to me.Below is an instruction that describes a task, Write a response that appropriately completes the request. {} contains tables such as {}. The descriptions of these tables are {}'''.format(db_id, tables,tables_description)\n",
    "    return TABLE_PROMPT.format(instruction,input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3395d5031269455eaab66fc3c27b6dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/21/2024 09:57:51 - INFO - dbgpt_hub.llm_base.adapter - Fine-tuning method: LoRA\n",
      "06/21/2024 09:58:10 - INFO - dbgpt_hub.llm_base.adapter - Merged 1 model checkpoint(s).\n",
      "06/21/2024 09:58:10 - INFO - dbgpt_hub.llm_base.adapter - Loaded fine-tuned model from checkpoint(s): /root/Neuvix/DB-GPT-HUB/dbgpt_hub/output/adapter/llama-3-sqlcoder-lora\n",
      "06/21/2024 09:58:28 - INFO - dbgpt_hub.llm_base.load_tokenizer - trainable params: 0 || all params: 8030261248 || trainable%: 0.0000\n",
      "06/21/2024 09:58:43 - INFO - dbgpt_hub.data_process.data_utils - Add pad token: <|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "            \"model_name_or_path\": \"/root/Neuvix/hugging-face/models--defog--llama-3-sqlcoder-8b\",\n",
    "            \"template\": \"llama2\",\n",
    "            \"finetuning_type\": \"lora\",\n",
    "            \"checkpoint_dir\": \"/root/Neuvix/DB-GPT-HUB/dbgpt_hub/output/adapter/llama-3-sqlcoder-lora\",\n",
    "            # \"predict_file_path\": \"/data1/zhengnanyan/NL2SQL/DB-GPT-Hub/dbgpt_hub/data/example_text2sql_dev.json\",\n",
    "            # \"predict_out_dir\": \"/data1/zhengnanyan/NL2SQL/DB-GPT-Hub/dbgpt_hub/output/\",\n",
    "            # \"predicted_out_filename\": \"pred_tp_mis.sql\",\n",
    "        }\n",
    "\n",
    "model = ChatModel(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 推理table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'change_driver_basic_info'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = prepare_table_data('有多少司机')\n",
    "response, _ = model.chat(query=query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change_driver_basic_info']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tables = response.split(\",\")\n",
    "pred_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 获取table的schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbgpt_hub.dataset_util.excel_processor import ExcelProcessor\n",
    "excel_processor = ExcelProcessor()\n",
    "\n",
    "DATA_PATH = \"dbgpt_hub/data\"\n",
    "DB_ID = \"tp_mis\"\n",
    "SCHEMA = \"schema\"\n",
    "\n",
    "def generate_sql_table_meta_data() -> Optional[Dict]:\n",
    "        # all_tables = excel_processor.read_excel(os.path.join(DATA_PATH, DB_ID, \"all_table.xlsx\"))\n",
    "        all_tables = excel_processor.read_excel(\"/root/Neuvix/DB-GPT-HUB/dbgpt_hub/data/tp_mis/all_table.xlsx\")\n",
    "        tables = [str(item[1]) for item in all_tables]\n",
    "        all_table_dict = {}\n",
    "        for item in tables:  # 一个item是一个表\n",
    "            table = item\n",
    "            # schema_file = os.path.join(DATA_PATH, DB_ID, SCHEMA, table + \".xlsx\")\n",
    "            schema_file = os.path.join(\"/root/Neuvix/DB-GPT-HUB/dbgpt_hub/data/tp_mis/schema\", table + \".xlsx\")\n",
    "            meta_data = excel_processor.read_excel(schema_file)\n",
    "            columns = []\n",
    "            column_comments = []\n",
    "            primary_key = None\n",
    "            for md in meta_data:\n",
    "                columns.append(md[1])\n",
    "                column_comments.append(md[3])\n",
    "                if md[4]==1:\n",
    "                    primary_key=md[1]\n",
    "            new_dict = {\n",
    "                 \"columns\":columns,\n",
    "                 \"column_comments\":column_comments,\n",
    "                 \"primary_key\":primary_key\n",
    "            }\n",
    "            all_table_dict[table] = new_dict\n",
    "        return all_table_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 推理SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_PROMPT = '''I want you to act as a SQL terminal in front of an example database, \\\n",
    "         you need only to return the sql command to me.Below is an instruction that describes a task, \\\n",
    "         Write a response that appropriately completes the request.\\n\"\n",
    "        \"##Instruction:\\n{}\\n###Input:\\n{}\\n\\n###Response:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want you to act as a SQL terminal in front of an example database,          you need only to return the sql command to me.Below is an instruction that describes a task,          Write a response that appropriately completes the request.\\n\"\\n        \"##Instruction:\\ntp_mis contains tables such as change_driver_basic_info. Table change_driver_basic_info has columns such as id, driver_no, driver_name, class_group. The comments of columns are id, 工号, 司机姓名, 班组. id is the primary key.\\n\\n###Input:\\n有多少司机\\n\\n###Response:'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_sql_data(input: Optional[str], pred_tables:Optional[List]) -> str:\n",
    "    all_table_dict = generate_sql_table_meta_data()\n",
    "    instruction_sql = (DB_ID + \" contains tables such as \" + \", \".join(pred_tables) + \". \")\n",
    "    for name in pred_tables:\n",
    "        columns = all_table_dict[name][\"columns\"]\n",
    "        instruction_sql += (\"Table \" + name + \" has columns such as \" + \", \".join(columns) + \". \")\n",
    "        comments = all_table_dict[name][\"column_comments\"]\n",
    "        instruction_sql += \"The comments of columns are \" + \", \".join(comments) + \". \"\n",
    "        primary_key = all_table_dict[name][\"primary_key\"]\n",
    "        instruction_sql += (primary_key + \" is the primary key.\"+ \"\\n\")\n",
    "    return SQL_PROMPT.format(instruction_sql,input)\n",
    "\n",
    "query = prepare_sql_data('有多少司机',pred_tables)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(driver_name) FROM tp_mis.change_driver_basic_info  ; '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response, _ = model.chat(query=query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 以下为无用代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/dbgpt_hub/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-20 11:48:01,922] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/dbgpt_hub/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def prepare_dataset(\n",
    "    predict_file_path: Optional[str] = None,\n",
    ") -> List[Dict]:\n",
    "    with open(predict_file_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    predict_data = [extract_sql_prompt_dataset(item) for item in data]\n",
    "    return predict_data\n",
    "\n",
    "\n",
    "def inference(model: ChatModel, predict_data: List[Dict], **input_kwargs):\n",
    "    res = []\n",
    "    # test\n",
    "    # for item in predict_data[:20]:\n",
    "    for item in tqdm(predict_data, desc=\"Inference Progress\", unit=\"item\"):\n",
    "        print(f\"item[input] \\n{item['input']}\")\n",
    "        response, _ = model.chat(query=item[\"input\"], history=[], **input_kwargs)\n",
    "        print(\"response: \",response)\n",
    "        res.append(response)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/20/2024 11:50:10 - INFO - dbgpt_hub.llm_base.adapter - Fine-tuning method: LoRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/20/2024 11:50:27 - INFO - dbgpt_hub.llm_base.adapter - Merged 1 model checkpoint(s).\n",
      "06/20/2024 11:50:27 - INFO - dbgpt_hub.llm_base.adapter - Loaded fine-tuned model from checkpoint(s): /root/Neuvix/DB-GPT-HUB/dbgpt_hub/output/adapter/llama-3-sqlcoder-lora\n",
      "06/20/2024 11:50:43 - INFO - dbgpt_hub.llm_base.load_tokenizer - trainable params: 0 || all params: 8030261248 || trainable%: 0.0000\n",
      "06/20/2024 11:50:54 - INFO - dbgpt_hub.data_process.data_utils - Add pad token: <|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "            \"model_name_or_path\": \"/root/Neuvix/hugging-face/models--defog--llama-3-sqlcoder-8b\",\n",
    "            \"template\": \"llama2\",\n",
    "            \"finetuning_type\": \"lora\",\n",
    "            \"checkpoint_dir\": \"/root/Neuvix/DB-GPT-HUB/dbgpt_hub/output/adapter/llama-3-sqlcoder-lora\",\n",
    "            # \"predict_file_path\": \"/data1/zhengnanyan/NL2SQL/DB-GPT-Hub/dbgpt_hub/data/example_text2sql_dev.json\",\n",
    "            # \"predict_out_dir\": \"/data1/zhengnanyan/NL2SQL/DB-GPT-Hub/dbgpt_hub/output/\",\n",
    "            # \"predicted_out_filename\": \"pred_tp_mis.sql\",\n",
    "        }\n",
    "\n",
    "model = ChatModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_file_path = \"/root/Neuvix/DB-GPT-HUB/dbgpt_hub/data/prompt_dev.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'I want you to act as a SQL terminal in front of an example database,          you need only to return the sql command to me.Below is an instruction that describes a task,          Write a response that appropriately completes the request.\\n##Instruction:\\nI want you to act as a SQL terminal in front of an example database, you need only to return the sql command to me.Below is an instruction that describes a task, Write a response that appropriately completes the request.\\n\"\\n##Instruction:\\ntp_mis contains tables such as change_shipping_basic_work_data. Table change_shipping_basic_work_data has columns such as id, vss_code, call_id, ship_owner, line_name, service_in, service_out, ship_length, ship_width, vssc_name, vssl_name, ship_state, berth_code, berth_direction, head_band, caudal_band, plan_berthing_date_time, act_berthind_date_time, plan_start_work_date_time, act_start_work_date_time, plan_finish_work_date_time, act_finish_work_date_time, import_start_date_time, import_finish_date_time, export_start_date_time, export_finish_date_time, plan_set_sail_date_time, act_set_sail_date_time, voyage_in, voyage_out, ship_attr, ship_attr_out, single_vessel, single_bridge, enter_ship_date, plan_work_box_quantity, act_work_box_quantity, work_quay_crane_nums, work_quay_crane_nos, plan_work_quay_crane_total_duration, act_work_quay_crane_total_duration, plan_on_the_berth_duration, act_on_the_berth_duration, plan_on_the_berth_eff, act_on_the_berth_eff, plan_single_vessel_eff, act_single_vessel_eff, plan_single_bridge_eff, act_single_bridge_eff, m_quay_crane_no, plan_m_eff, act_m_eff, plan_m_box_quantity, act_m_box_quantity, plan_m_duration, act_m_duration, import_box_quantity, export_box_quantity, import_overrun_box_quantity, import_danger_box_quantity, import_code_storage_box_quantity, export_overrun_box_quantity, export_danger_box_quantity, export_code_storage_box_quantity, hatch_cover_nums, create_date_time, update_date_time, berth_pos_x. The comments of columns are 主键, 船舶代码, 船舶ID, 船公司, 航线名, 进口航线, 出口航线, 船长, 船宽, 中文船名, 英文船名, 船舶状态, 泊位, 泊位靠泊方向, 头带, 尾带, 计划靠泊时间, 实际靠泊时间, 计划开工时间, 实际开工时间, 计划完工时间, 实际完工时间, 进口开始时间, 进口完工时间, 出口开始时间, 出口完工时间, 计划开船时间, 实际开船时间, 进口航次, 出口航次, 进口贸易属性, 出口贸易属性, 单船效率, 单桥效率, 计划进船时间, 计划作业箱量, 实际作业箱量, 作业岸桥数量, 作业岸桥号, 计划作业岸桥总时长, 实际作业岸桥总时长, 计划在泊时长, 实际在泊时长, 计划在泊效率, 实际在泊效率, 计划单船效率, 实际单船效率, 计划单桥效率, 实际单桥效率, M岸桥号, 计划M效率, 实际M效率, 计划M箱量, 实际M箱量, 计划M时长, 实际M时长, 进口箱量, 出口箱量, 进口超限箱量, 进口危险品箱量, 进口冷藏箱量, 出口超限箱量, 出口危险品箱量, 出口冷藏箱量, 舱盖板数, 记录创建时间, 记录修改时间, 泊位管理计划-头齐. id is the primary key.\\n\\n\\n###Input:\\n###Input:\\n查询所有计划进港的船名\\n\\n###Response:\\n\\n###Response:'},\n",
       " {'input': 'I want you to act as a SQL terminal in front of an example database,          you need only to return the sql command to me.Below is an instruction that describes a task,          Write a response that appropriately completes the request.\\n##Instruction:\\nI want you to act as a SQL terminal in front of an example database, you need only to return the sql command to me.Below is an instruction that describes a task, Write a response that appropriately completes the request.\\n\"\\n##Instruction:\\ntp_mis contains tables such as change_shipping_basic_work_data. Table change_shipping_basic_work_data has columns such as id, vss_code, call_id, ship_owner, line_name, service_in, service_out, ship_length, ship_width, vssc_name, vssl_name, ship_state, berth_code, berth_direction, head_band, caudal_band, plan_berthing_date_time, act_berthind_date_time, plan_start_work_date_time, act_start_work_date_time, plan_finish_work_date_time, act_finish_work_date_time, import_start_date_time, import_finish_date_time, export_start_date_time, export_finish_date_time, plan_set_sail_date_time, act_set_sail_date_time, voyage_in, voyage_out, ship_attr, ship_attr_out, single_vessel, single_bridge, enter_ship_date, plan_work_box_quantity, act_work_box_quantity, work_quay_crane_nums, work_quay_crane_nos, plan_work_quay_crane_total_duration, act_work_quay_crane_total_duration, plan_on_the_berth_duration, act_on_the_berth_duration, plan_on_the_berth_eff, act_on_the_berth_eff, plan_single_vessel_eff, act_single_vessel_eff, plan_single_bridge_eff, act_single_bridge_eff, m_quay_crane_no, plan_m_eff, act_m_eff, plan_m_box_quantity, act_m_box_quantity, plan_m_duration, act_m_duration, import_box_quantity, export_box_quantity, import_overrun_box_quantity, import_danger_box_quantity, import_code_storage_box_quantity, export_overrun_box_quantity, export_danger_box_quantity, export_code_storage_box_quantity, hatch_cover_nums, create_date_time, update_date_time, berth_pos_x. The comments of columns are 主键, 船舶代码, 船舶ID, 船公司, 航线名, 进口航线, 出口航线, 船长, 船宽, 中文船名, 英文船名, 船舶状态, 泊位, 泊位靠泊方向, 头带, 尾带, 计划靠泊时间, 实际靠泊时间, 计划开工时间, 实际开工时间, 计划完工时间, 实际完工时间, 进口开始时间, 进口完工时间, 出口开始时间, 出口完工时间, 计划开船时间, 实际开船时间, 进口航次, 出口航次, 进口贸易属性, 出口贸易属性, 单船效率, 单桥效率, 计划进船时间, 计划作业箱量, 实际作业箱量, 作业岸桥数量, 作业岸桥号, 计划作业岸桥总时长, 实际作业岸桥总时长, 计划在泊时长, 实际在泊时长, 计划在泊效率, 实际在泊效率, 计划单船效率, 实际单船效率, 计划单桥效率, 实际单桥效率, M岸桥号, 计划M效率, 实际M效率, 计划M箱量, 实际M箱量, 计划M时长, 实际M时长, 进口箱量, 出口箱量, 进口超限箱量, 进口危险品箱量, 进口冷藏箱量, 出口超限箱量, 出口危险品箱量, 出口冷藏箱量, 舱盖板数, 记录创建时间, 记录修改时间, 泊位管理计划-头齐. id is the primary key.\\n\\n\\n###Input:\\n###Input:\\n查询所有等待进港船的船名\\n\\n###Response:\\n\\n###Response:'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data = prepare_dataset(dev_file_path)\n",
    "predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress:   0%|          | 0/2 [00:00<?, ?item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item[input] \n",
      "I want you to act as a SQL terminal in front of an example database,          you need only to return the sql command to me.Below is an instruction that describes a task,          Write a response that appropriately completes the request.\n",
      "##Instruction:\n",
      "I want you to act as a SQL terminal in front of an example database, you need only to return the sql command to me.Below is an instruction that describes a task, Write a response that appropriately completes the request.\n",
      "\"\n",
      "##Instruction:\n",
      "tp_mis contains tables such as change_shipping_basic_work_data. Table change_shipping_basic_work_data has columns such as id, vss_code, call_id, ship_owner, line_name, service_in, service_out, ship_length, ship_width, vssc_name, vssl_name, ship_state, berth_code, berth_direction, head_band, caudal_band, plan_berthing_date_time, act_berthind_date_time, plan_start_work_date_time, act_start_work_date_time, plan_finish_work_date_time, act_finish_work_date_time, import_start_date_time, import_finish_date_time, export_start_date_time, export_finish_date_time, plan_set_sail_date_time, act_set_sail_date_time, voyage_in, voyage_out, ship_attr, ship_attr_out, single_vessel, single_bridge, enter_ship_date, plan_work_box_quantity, act_work_box_quantity, work_quay_crane_nums, work_quay_crane_nos, plan_work_quay_crane_total_duration, act_work_quay_crane_total_duration, plan_on_the_berth_duration, act_on_the_berth_duration, plan_on_the_berth_eff, act_on_the_berth_eff, plan_single_vessel_eff, act_single_vessel_eff, plan_single_bridge_eff, act_single_bridge_eff, m_quay_crane_no, plan_m_eff, act_m_eff, plan_m_box_quantity, act_m_box_quantity, plan_m_duration, act_m_duration, import_box_quantity, export_box_quantity, import_overrun_box_quantity, import_danger_box_quantity, import_code_storage_box_quantity, export_overrun_box_quantity, export_danger_box_quantity, export_code_storage_box_quantity, hatch_cover_nums, create_date_time, update_date_time, berth_pos_x. The comments of columns are 主键, 船舶代码, 船舶ID, 船公司, 航线名, 进口航线, 出口航线, 船长, 船宽, 中文船名, 英文船名, 船舶状态, 泊位, 泊位靠泊方向, 头带, 尾带, 计划靠泊时间, 实际靠泊时间, 计划开工时间, 实际开工时间, 计划完工时间, 实际完工时间, 进口开始时间, 进口完工时间, 出口开始时间, 出口完工时间, 计划开船时间, 实际开船时间, 进口航次, 出口航次, 进口贸易属性, 出口贸易属性, 单船效率, 单桥效率, 计划进船时间, 计划作业箱量, 实际作业箱量, 作业岸桥数量, 作业岸桥号, 计划作业岸桥总时长, 实际作业岸桥总时长, 计划在泊时长, 实际在泊时长, 计划在泊效率, 实际在泊效率, 计划单船效率, 实际单船效率, 计划单桥效率, 实际单桥效率, M岸桥号, 计划M效率, 实际M效率, 计划M箱量, 实际M箱量, 计划M时长, 实际M时长, 进口箱量, 出口箱量, 进口超限箱量, 进口危险品箱量, 进口冷藏箱量, 出口超限箱量, 出口危险品箱量, 出口冷藏箱量, 舱盖板数, 记录创建时间, 记录修改时间, 泊位管理计划-头齐. id is the primary key.\n",
      "\n",
      "\n",
      "###Input:\n",
      "###Input:\n",
      "查询所有计划进港的船名\n",
      "\n",
      "###Response:\n",
      "\n",
      "###Response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress:  50%|█████     | 1/2 [00:02<00:02,  2.77s/item]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  SELECT vssc_name FROM change_shipping_basic_work_data WHERE ship_state = \"计划进港\"\n",
      "item[input] \n",
      "I want you to act as a SQL terminal in front of an example database,          you need only to return the sql command to me.Below is an instruction that describes a task,          Write a response that appropriately completes the request.\n",
      "##Instruction:\n",
      "I want you to act as a SQL terminal in front of an example database, you need only to return the sql command to me.Below is an instruction that describes a task, Write a response that appropriately completes the request.\n",
      "\"\n",
      "##Instruction:\n",
      "tp_mis contains tables such as change_shipping_basic_work_data. Table change_shipping_basic_work_data has columns such as id, vss_code, call_id, ship_owner, line_name, service_in, service_out, ship_length, ship_width, vssc_name, vssl_name, ship_state, berth_code, berth_direction, head_band, caudal_band, plan_berthing_date_time, act_berthind_date_time, plan_start_work_date_time, act_start_work_date_time, plan_finish_work_date_time, act_finish_work_date_time, import_start_date_time, import_finish_date_time, export_start_date_time, export_finish_date_time, plan_set_sail_date_time, act_set_sail_date_time, voyage_in, voyage_out, ship_attr, ship_attr_out, single_vessel, single_bridge, enter_ship_date, plan_work_box_quantity, act_work_box_quantity, work_quay_crane_nums, work_quay_crane_nos, plan_work_quay_crane_total_duration, act_work_quay_crane_total_duration, plan_on_the_berth_duration, act_on_the_berth_duration, plan_on_the_berth_eff, act_on_the_berth_eff, plan_single_vessel_eff, act_single_vessel_eff, plan_single_bridge_eff, act_single_bridge_eff, m_quay_crane_no, plan_m_eff, act_m_eff, plan_m_box_quantity, act_m_box_quantity, plan_m_duration, act_m_duration, import_box_quantity, export_box_quantity, import_overrun_box_quantity, import_danger_box_quantity, import_code_storage_box_quantity, export_overrun_box_quantity, export_danger_box_quantity, export_code_storage_box_quantity, hatch_cover_nums, create_date_time, update_date_time, berth_pos_x. The comments of columns are 主键, 船舶代码, 船舶ID, 船公司, 航线名, 进口航线, 出口航线, 船长, 船宽, 中文船名, 英文船名, 船舶状态, 泊位, 泊位靠泊方向, 头带, 尾带, 计划靠泊时间, 实际靠泊时间, 计划开工时间, 实际开工时间, 计划完工时间, 实际完工时间, 进口开始时间, 进口完工时间, 出口开始时间, 出口完工时间, 计划开船时间, 实际开船时间, 进口航次, 出口航次, 进口贸易属性, 出口贸易属性, 单船效率, 单桥效率, 计划进船时间, 计划作业箱量, 实际作业箱量, 作业岸桥数量, 作业岸桥号, 计划作业岸桥总时长, 实际作业岸桥总时长, 计划在泊时长, 实际在泊时长, 计划在泊效率, 实际在泊效率, 计划单船效率, 实际单船效率, 计划单桥效率, 实际单桥效率, M岸桥号, 计划M效率, 实际M效率, 计划M箱量, 实际M箱量, 计划M时长, 实际M时长, 进口箱量, 出口箱量, 进口超限箱量, 进口危险品箱量, 进口冷藏箱量, 出口超限箱量, 出口危险品箱量, 出口冷藏箱量, 舱盖板数, 记录创建时间, 记录修改时间, 泊位管理计划-头齐. id is the primary key.\n",
      "\n",
      "\n",
      "###Input:\n",
      "###Input:\n",
      "查询所有等待进港船的船名\n",
      "\n",
      "###Response:\n",
      "\n",
      "###Response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 2/2 [00:03<00:00,  1.78s/item]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  SELECT vssc_name FROM change_shipping_basic_work_data WHERE ship_state=\"待进港\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = inference(model, predict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT chi_ship_name,nationality FROM tp_mix.change_ship_archives_basic_info where chi_ship_name=\"csc18\";'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template='''I want you to act as a SQL terminal in front of an example database,          \n",
    "you need only to return the sql command to me.Below is an instruction that describes a task,          \n",
    "Write a response that appropriately completes the request.\\n##Instruction:\\nI want you to act as a SQL terminal in front of an example database, you need only to return the sql command to me.Below is an instruction that describes a task, Write a response that appropriately completes the request.\\n\"\\n##Instruction:\\ntp_mix contains tables such as change_ship_archives_basic_info. Table change_ship_archives_basic_info has columns such as id, ship_code, chi_and_eng_ship_name, nationality, ship_call_number, ship_imo_number, vessel_class, box_total, total_tonnage_of_ships, net_tonnage_of_ships, ships_deadweight_tonnage, ship_length, bow_position, chimney_position, ship_type_depth, ship_width, ship_height, ship_speed, date_of_construction, ship_type, Liner_identification, group_code, mmsi_code, bei_number, number_of_hatches, number_of_bow_shells, number_of_hatch_covers, empty_draft_tonnage, Heavy_load_draft_tonnage, number_of_deck_starting_layer, beihao_arrangement_order, slot_way, stowage_scheme, belonging_to_the_dock, create_date_time, del_flag, chi_ship_name, eng_ship_name. The comments of columns are 主键ID, 船舶代码, 中英文船名, 国籍, 船舶呼号, 船舶IMO号, 船舶等级？, 总箱量, 船舶总吨位, 船舶净吨位, 船舶载重吨, 船舶长度, 船头位置, 烟囱位置, 船舶型深, 船舶宽度, 船舶高度, 船舶速度, 建造日期, 船舶类型, 班轮标识, 集团代码, MMSI代码, 贝数量, 舱口数, 船头贝数, 舱盖数, 空载吃水吨位, 重载吃水吨位, 甲板起始层序号, 贝号排列顺序, slot_way?, stowage_scheme?, 所属码头, 记录创建时间, 删除标记。0-未删除；1-已删除, 中文船名, 英文船名. id is the primary key.\\n\\n\\n###Input:\\n###Input:\\n{}\\n\\n###Response:\\n\\n###Response:'''\n",
    "query = prompt_template.format(\"显示船舶csc18的国籍\")\n",
    "response, _ = model.chat(query=query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbgpt_hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
